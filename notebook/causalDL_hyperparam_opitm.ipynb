{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "causalDL_hyperparam_opitm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "background_execution": "on"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7pkzswPCGbh",
        "outputId": "f33fa90d-3269-4405-d7f6-e46cb7f34c13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir('/content/drive/My Drive/CausalDL/')"
      ],
      "metadata": {
        "id": "9-11FtcRDju1"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvK3h_cfWLd0",
        "outputId": "3e2b1755-bec0-43bb-f654-e1736a99f8cf"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri May  6 17:09:22 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P0    41W / 300W |    627MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load LIDH Data"
      ],
      "metadata": {
        "id": "Kitx6W6AChgp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.data_reader import read_IHDP_data, read_SIPP_data\n",
        "\n",
        "#data=read_SIPP_data(file = './data/SIPP/sipp1991.dta')\n",
        "data=read_IHDP_data(training_data='./data/IHDP/ihdp_npci_1-100.train.npz',testing_data='./data/IHDP/ihdp_npci_1-100.test.npz')"
      ],
      "metadata": {
        "id": "ZjMOoC28CewA"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q tensorflow==2.8.0\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import datetime\n",
        "#Colab command to allow us to run Colab in TF2\n",
        "%load_ext tensorboard \n",
        "\n",
        "# Install Keras Tuner\n",
        "!pip install keras-tuner==1.0.4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "snrnvanWEC0B",
        "outputId": "ddc36752-8297-445d-a0fa-0b21497c237f"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n",
            "Requirement already satisfied: keras-tuner==1.0.4 in /usr/local/lib/python3.7/dist-packages (1.0.4)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.4) (1.0.4)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.4) (5.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.4) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.4) (1.21.6)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.4) (2.8.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.4) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner==1.0.4) (2.23.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.4) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.4) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.4) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.4) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.4) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.4) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.4) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner==1.0.4) (1.0.18)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner==1.0.4) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner==1.0.4) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner==1.0.4) (3.0.8)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner==1.0.4) (0.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner==1.0.4) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner==1.0.4) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner==1.0.4) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner==1.0.4) (1.24.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.4) (1.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.4) (0.37.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.4) (1.44.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.4) (1.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.4) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.4) (1.35.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.4) (3.17.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.4) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.4) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner==1.0.4) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner==1.0.4) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner==1.0.4) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner==1.0.4) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner==1.0.4) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner==1.0.4) (4.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner==1.0.4) (4.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner==1.0.4) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner==1.0.4) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner==1.0.4) (3.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TerminateOnNaN\n",
        "\n",
        "from model.model_loss import Base_Dragon_Loss, TarReg_Loss, MSE_Loss, CFRNet_Loss\n",
        "from model.model_metrics import AIPW_Metrics, TarReg_Metrics, Base_Metrics"
      ],
      "metadata": {
        "id": "usyi8ZzwG4BH"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_prediction(data, model):\n",
        "    \"\"\"\n",
        "    Compute model predicted ATE(average treatment effect) and compare to ground truth (if exists)\n",
        "    \"\"\"\n",
        "    concat_pred=model.predict(data['x'])\n",
        "    #dont forget to rescale the outcome before estimation!\n",
        "    y0_pred = data['y_scaler'].inverse_transform(concat_pred[:, 0].reshape(-1, 1))\n",
        "    y1_pred = data['y_scaler'].inverse_transform(concat_pred[:, 1].reshape(-1, 1))\n",
        "    \n",
        "    #predicted CATE\n",
        "    cate_pred=y1_pred-y0_pred\n",
        "    \n",
        "    data_save = {}      \n",
        "    data_save['cate_pred'] = cate_pred\n",
        "    \n",
        "    if 'mu_1' in data.keys() or 'mu_0' in data.keys():\n",
        "        cate_true=data['mu_1']-data['mu_0'] #Hill's noiseless true values\n",
        "        data_save['cate_true'] = cate_true\n",
        "        print(\"Actual ATE:\", cate_true.mean(),'\\n\\n')\n",
        "    ate_pred=tf.reduce_mean(cate_pred)\n",
        "    print(\"Estimated ATE:\", ate_pred.numpy(),'\\n\\n')\n",
        "    data_save['ate_pred'] = ate_pred\n",
        "    \n",
        "    return data_save"
      ],
      "metadata": {
        "id": "iHfy8cNFNteK"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine tune CFRNet"
      ],
      "metadata": {
        "id": "fuzFQbBjPJXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "from keras_tuner.tuners import RandomSearch\n",
        "\n",
        "def make_hypercfrnet(hp):\n",
        "    \"\"\"\n",
        "    Neural net predictive model. The dragon has three heads.\n",
        "    :param input_dim:\n",
        "    :param reg:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # hp.Choice takes hyperparam name, list of options, and default\n",
        "    reg_l2=hp.Choice('l2',[.1,.01,.001],default=.01)\n",
        "    input_dim=25\n",
        "    inputs = Input(shape=(input_dim,), name='input')\n",
        "\n",
        "    # representation\n",
        "    rep_units = hp.Choice('rep_units', [20, 25, 50,100],default=25)\n",
        "    phi = Dense(units=rep_units, activation='elu', kernel_initializer='RandomNormal',name='phi_1')(inputs)\n",
        "    for i in range(hp.Int('rep_layers', 1, 2, default=1)):\n",
        "      #pretty nifty way to dynamically add more layers!\n",
        "      phi = Dense(units=rep_units, activation='elu', kernel_initializer='RandomNormal',name='phi_'+str(i+2))(phi)\n",
        "\n",
        "    # HYPOTHESIS\n",
        "    hyp_units = hp.Choice('hyp_units', [20,25, 50,100],default=25)\n",
        "    y0_hidden = Dense(units=hyp_units, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y0_hidden_1')(phi)\n",
        "    y1_hidden = Dense(units=hyp_units, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y1_hidden_1')(phi)\n",
        "    for i in range(hp.Int('hyp_layers', 1, 3, default=2)):\n",
        "      y0_hidden = Dense(units=hyp_units, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y0_hidden_'+str(i+2))(y0_hidden)\n",
        "      y1_hidden = Dense(units=hyp_units, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y1_hidden_'+str(i+2))(y1_hidden)\n",
        "    \n",
        "    # OUTPUT\n",
        "    y0_predictions = Dense(units=1, activation=None, kernel_regularizer=regularizers.l2(reg_l2), name='y0_predictions')(y0_hidden)\n",
        "    y1_predictions = Dense(units=1, activation=None, kernel_regularizer=regularizers.l2(reg_l2), name='y1_predictions')(y1_hidden)\n",
        "\n",
        "    concat_pred = Concatenate(1)([y0_predictions, y1_predictions,phi])\n",
        "    model = Model(inputs=inputs, outputs=concat_pred)\n",
        "    \n",
        "    sgd_lr = 1e-5\n",
        "    #momentum = 0.9\n",
        "    \n",
        "    #optimizer=SGD(lr=sgd_lr, momentum=momentum, nesterov=True)\n",
        "    cfrnet_loss=CFRNet_Loss(alpha=1.0)\n",
        "    model.compile(optimizer=Adam(learning_rate=sgd_lr),\n",
        "                       loss=cfrnet_loss,\n",
        "                  metrics=[cfrnet_loss,cfrnet_loss.regression_loss,cfrnet_loss.mmdsq_loss])\n",
        "    # model.compile(optimizer=SGD(lr=sgd_lr, momentum=momentum, nesterov=True),\n",
        "    #                   loss=regression_loss,\n",
        "    #              metrics=regression_loss)\n",
        "\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "dxeIET7uENjX"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_tuner.engine import tuner_utils\n",
        "from tensorboard.plugins.hparams import api as hparams_api\n",
        "!rm -rf cfr_dir\n",
        "\n",
        "class CFRNetTuner(kt.Tuner):\n",
        "\n",
        "  def run_trial(self, trial,dataset,*fit_args, **fit_kwargs):\n",
        "      # *args and **kwargs in Python are positional (list) and keyword (dict) arguments\n",
        "      verbose = fit_kwargs['verbose']\n",
        "\n",
        "      log_dir=self.project_dir+'/trial_'+trial.trial_id\n",
        "      hp = trial.hyperparameters\n",
        "      \n",
        "      batch_size = hp.Int('batch_size', 64, 256, step=64, default=64)\n",
        "      stopping_patience=hp.Int('batch_size', 5, 15, step=5, default=5)\n",
        "\n",
        "      #some of this hacky code will hopefully go away as Keras Tuner get's more polished\n",
        "      hparams = tuner_utils.convert_hyperparams_to_hparams(trial.hyperparameters)\n",
        "      file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
        "      file_writer.set_as_default()\n",
        "      \n",
        "      tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "      hparams_callback = hparams_api.KerasCallback(\n",
        "                        writer=log_dir,\n",
        "                        hparams=hparams,\n",
        "                        #I prepend trial_ here to get it to save nicely. Hopefully will be fixed in future version of KT.\n",
        "                        trial_id='trial_'+trial.trial_id) \n",
        "      metrics_callback=Base_Metrics(dataset,verbose=verbose)\n",
        "      callbacks = [\n",
        "              TerminateOnNaN(),\n",
        "              EarlyStopping(monitor='val_loss', patience=stopping_patience, min_delta=0.0001),\n",
        "              ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, verbose=verbose, mode='auto',\n",
        "                                min_delta=0, cooldown=0, min_lr=0),\n",
        "              metrics_callback,\n",
        "              tensorboard_callback,\n",
        "              hparams_callback\n",
        "          ]\n",
        "\n",
        "      \n",
        "      model = self.hypermodel.build(hp)\n",
        "      model.fit(x=fit_args[0],y=fit_args[1],\n",
        "                 callbacks=callbacks,\n",
        "                  validation_split=fit_kwargs['validation_split'],\n",
        "                  epochs=fit_kwargs['epochs'],\n",
        "                  batch_size=batch_size, verbose=verbose)\n",
        "      \n",
        "      #give the metric to the hyperparameter optimization algorithm\n",
        "      concat_pred=model.predict(data['x'])\n",
        "      pehe_nn=metrics_callback.PEHEnn(concat_pred)\n",
        "      self.oracle.update_trial(trial.trial_id, {'cate_nn_err': tf.sqrt(pehe_nn)})\n",
        "      self.save_model(trial.trial_id, model)\n"
      ],
      "metadata": {
        "id": "bMJblIIPETq5"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "yt = np.concatenate([data['ys'], data['t']], 1)\n",
        "\n",
        "tuner = CFRNetTuner(\n",
        "    #the oracle is the hyperoptimization algorithm\n",
        "    oracle=kt.oracles.BayesianOptimization(\n",
        "        objective=kt.Objective('cate_nn_err', 'min'),\n",
        "        max_trials=10, #were trying to keep this quick for you.\n",
        "        #You probably want to do as many trials as your resources allow if you see variance between runs\n",
        "        seed=0    \n",
        "),\n",
        "        directory='cfr_dir',\n",
        "        project_name='cfr_tune',\n",
        "    hypermodel=make_hypercfrnet\n",
        "    )\n",
        "tuner.search(data, data['x'],yt, epochs=500,validation_split=.2,verbose=2)\n",
        "\n",
        "best_trial=tuner.oracle.get_best_trials(num_trials=1)[0]\n",
        "print(\"BEST TRIAL ID:\",best_trial.trial_id)\n",
        "best_model=tuner.load_model(best_trial)"
      ],
      "metadata": {
        "id": "LPYo8ovV3JoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_trial.hyperparameters.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhLF1tGCgZkf",
        "outputId": "d39ec06d-1bf0-4037-e664-5ee17c05dcfd"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'batch_size': 64,\n",
              " 'hyp_layers': 2,\n",
              " 'hyp_units': 25,\n",
              " 'l2': 0.1,\n",
              " 'rep_layers': 1,\n",
              " 'rep_units': 50}"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save predicted result\n",
        "data_save_cfr=compute_prediction(data, best_model)\n",
        "np.save('./save/pred_result/tune_result_{}.npy'.format(\"cfrnet\" + '_' + \"IHDP\"), data_save_cfr) "
      ],
      "metadata": {
        "id": "yitiFa0IKfDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine Tune DragonNet"
      ],
      "metadata": {
        "id": "ukXapYvGPNWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#https://github.com/kochbj/Deep-Learning-for-Causal-Inference\n",
        "\n",
        "def make_hyperdragonnet(hp):\n",
        "    \"\"\"\n",
        "    Neural net predictive model. The dragon has three heads.\n",
        "    :param input_dim:\n",
        "    :param reg:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # hp.Choice takes hyperparam name, list of options, and default\n",
        "    reg_l2=hp.Choice('l2',[.1,.01,.001],default=.01)\n",
        "    input_dim=25\n",
        "    inputs = Input(shape=(input_dim,), name='input')\n",
        "\n",
        "    # representation\n",
        "    rep_units = hp.Choice('rep_units', [50,100,200],default=200)\n",
        "    phi = Dense(units=rep_units, activation='elu', kernel_initializer='RandomNormal',name='phi_1')(inputs)\n",
        "    for i in range(hp.Int('rep_layers', 1, 2, 3, default=1)):\n",
        "      #pretty nifty way to dynamically add more layers!\n",
        "      phi = Dense(units=rep_units, activation='elu', kernel_initializer='RandomNormal',name='phi_'+str(i+2))(phi)\n",
        "\n",
        "    # HYPOTHESIS\n",
        "    hyp_units = hp.Choice('hyp_units', [20,50,100,200],default=100)\n",
        "    y0_hidden = Dense(units=hyp_units, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y0_hidden_1')(phi)\n",
        "    y1_hidden = Dense(units=hyp_units, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y1_hidden_1')(phi)\n",
        "    for i in range(hp.Int('hyp_layers', 1, 3, default=2)):\n",
        "      y0_hidden = Dense(units=hyp_units, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y0_hidden_'+str(i+2))(y0_hidden)\n",
        "      y1_hidden = Dense(units=hyp_units, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y1_hidden_'+str(i+2))(y1_hidden)\n",
        "    \n",
        "    # OUTPUT\n",
        "    y0_predictions = Dense(units=1, activation=None, kernel_regularizer=regularizers.l2(reg_l2), name='y0_predictions')(y0_hidden)\n",
        "    y1_predictions = Dense(units=1, activation=None, kernel_regularizer=regularizers.l2(reg_l2), name='y1_predictions')(y1_hidden)\n",
        "    \n",
        "    t_prediction = Dense(units=1,activation=None,name='t_prediction')(phi)\n",
        "    concat_pred = Concatenate(1)([y0_predictions, y1_predictions,t_prediction, phi])\n",
        "    model = Model(inputs=inputs, outputs=concat_pred)\n",
        "    \n",
        "    sgd_lr = 1e-5\n",
        "    momentum = 0.9\n",
        "    \n",
        "    optimizer=SGD(lr=sgd_lr, momentum=momentum, nesterov=True)\n",
        "    aipw_loss=Base_Dragon_Loss(alpha=1.0)\n",
        "    model.compile(optimizer=SGD(lr=sgd_lr, momentum=momentum, nesterov=True),\n",
        "                      loss=aipw_loss,\n",
        "                 metrics=[aipw_loss,aipw_loss.regression_loss,aipw_loss.treatment_acc])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "hQJcYiVaPDdi"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_tuner.engine import tuner_utils\n",
        "from tensorboard.plugins.hparams import api as hparams_api\n",
        "!rm -rf dragon_dir\n",
        "\n",
        "class DragonNetTuner(kt.Tuner):\n",
        "\n",
        "  def run_trial(self, trial,dataset,*fit_args, **fit_kwargs):\n",
        "      # *args and **kwargs in Python are positional (list) and keyword (dict) arguments\n",
        "      verbose = fit_kwargs['verbose']\n",
        "\n",
        "      log_dir=self.project_dir+'/trial_'+trial.trial_id\n",
        "      hp = trial.hyperparameters\n",
        "      \n",
        "      batch_size = hp.Int('batch_size', 64, 256, step=64, default=64)\n",
        "      stopping_patience=hp.Int('batch_size', 5, 15, step=5, default=5)\n",
        "\n",
        "      #some of this hacky code will hopefully go away as Keras Tuner get's more polished\n",
        "      hparams = tuner_utils.convert_hyperparams_to_hparams(trial.hyperparameters)\n",
        "      file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
        "      file_writer.set_as_default()\n",
        "      \n",
        "      tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "      hparams_callback = hparams_api.KerasCallback(\n",
        "                        writer=log_dir,\n",
        "                        hparams=hparams,\n",
        "                        #I prepend trial_ here to get it to save nicely. Hopefully will be fixed in future version of KT.\n",
        "                        trial_id='trial_'+trial.trial_id) \n",
        "      metrics_callback=AIPW_Metrics(dataset,verbose=verbose)\n",
        "      callbacks = [\n",
        "              TerminateOnNaN(),\n",
        "              EarlyStopping(monitor='val_loss', patience=stopping_patience, min_delta=0.),\n",
        "              ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, verbose=verbose, mode='auto',\n",
        "                                min_delta=0, cooldown=0, min_lr=0),\n",
        "              metrics_callback,\n",
        "              tensorboard_callback,\n",
        "              hparams_callback\n",
        "          ]\n",
        "\n",
        "      \n",
        "      model = self.hypermodel.build(hp)\n",
        "      model.fit(x=fit_args[0],y=fit_args[1],\n",
        "                 callbacks=callbacks,\n",
        "                  validation_split=fit_kwargs['validation_split'],\n",
        "                  epochs=fit_kwargs['epochs'],\n",
        "                  batch_size=batch_size, verbose=verbose)\n",
        "      \n",
        "      #give the metric to the hyperparameter optimization algorithm\n",
        "      concat_pred=model.predict(data['x'])\n",
        "      pehe_nn=metrics_callback.PEHEnn(concat_pred)\n",
        "      self.oracle.update_trial(trial.trial_id, {'cate_nn_err': tf.sqrt(pehe_nn)})\n",
        "      self.save_model(trial.trial_id, model)\n"
      ],
      "metadata": {
        "id": "Ol7c38_aQW5K"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = DragonNetTuner(\n",
        "    #the oracle is the hyperoptimization algorithm\n",
        "    oracle=kt.oracles.BayesianOptimization(\n",
        "        objective=kt.Objective('cate_nn_err', 'min'),\n",
        "        max_trials=10, #were trying to keep this quick for you.\n",
        "        #You probably want to do as many trials as your resources allow if you see variance between runs\n",
        "        seed=0    \n",
        "),\n",
        "        directory='dragon_dir',\n",
        "        project_name='helloworld',\n",
        "    hypermodel=make_hyperdragonnet\n",
        "    )\n",
        "tuner.search(data, data['x'],yt, epochs=300,validation_split=.2,verbose=2)\n",
        "\n",
        "best_trial=tuner.oracle.get_best_trials(num_trials=1)[0]\n",
        "print(\"BEST TRIAL ID:\",best_trial.trial_id)\n",
        "best_dragon_model=tuner.load_model(best_trial)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zwjM7ydRLCq",
        "outputId": "417a9e49-a943-4e28-a2d1-61fe916ce5c3"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 01m 14s]\n",
            "cate_nn_err: 1.730276346206665\n",
            "\n",
            "Best cate_nn_err So Far: 1.5806220769882202\n",
            "Total elapsed time: 00h 15m 20s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "BEST TRIAL ID: 56df958159155b3dcb38156758f63143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_dragon_model.get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-gIeDvuuLMb",
        "outputId": "70d96393-58e6-4f4d-d9c1-5e10f5fd3a99"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_layers': [['input', 0, 0]],\n",
              " 'layers': [{'class_name': 'InputLayer',\n",
              "   'config': {'batch_input_shape': (None, 25),\n",
              "    'dtype': 'float32',\n",
              "    'name': 'input',\n",
              "    'ragged': False,\n",
              "    'sparse': False},\n",
              "   'inbound_nodes': [],\n",
              "   'name': 'input'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'elu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'RandomNormal',\n",
              "     'config': {'mean': 0.0, 'seed': None, 'stddev': 0.05}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'phi_1',\n",
              "    'trainable': True,\n",
              "    'units': 50,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['input', 0, 0, {}]]],\n",
              "   'name': 'phi_1'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'elu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'RandomNormal',\n",
              "     'config': {'mean': 0.0, 'seed': None, 'stddev': 0.05}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'phi_2',\n",
              "    'trainable': True,\n",
              "    'units': 50,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['phi_1', 0, 0, {}]]],\n",
              "   'name': 'phi_2'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'elu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L2',\n",
              "     'config': {'l2': 0.10000000149011612}},\n",
              "    'name': 'y0_hidden_1',\n",
              "    'trainable': True,\n",
              "    'units': 50,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['phi_2', 0, 0, {}]]],\n",
              "   'name': 'y0_hidden_1'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'elu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L2',\n",
              "     'config': {'l2': 0.10000000149011612}},\n",
              "    'name': 'y1_hidden_1',\n",
              "    'trainable': True,\n",
              "    'units': 50,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['phi_2', 0, 0, {}]]],\n",
              "   'name': 'y1_hidden_1'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'elu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L2',\n",
              "     'config': {'l2': 0.10000000149011612}},\n",
              "    'name': 'y0_hidden_2',\n",
              "    'trainable': True,\n",
              "    'units': 50,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['y0_hidden_1', 0, 0, {}]]],\n",
              "   'name': 'y0_hidden_2'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'elu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L2',\n",
              "     'config': {'l2': 0.10000000149011612}},\n",
              "    'name': 'y1_hidden_2',\n",
              "    'trainable': True,\n",
              "    'units': 50,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['y1_hidden_1', 0, 0, {}]]],\n",
              "   'name': 'y1_hidden_2'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'elu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L2',\n",
              "     'config': {'l2': 0.10000000149011612}},\n",
              "    'name': 'y0_hidden_3',\n",
              "    'trainable': True,\n",
              "    'units': 50,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['y0_hidden_2', 0, 0, {}]]],\n",
              "   'name': 'y0_hidden_3'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'elu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L2',\n",
              "     'config': {'l2': 0.10000000149011612}},\n",
              "    'name': 'y1_hidden_3',\n",
              "    'trainable': True,\n",
              "    'units': 50,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['y1_hidden_2', 0, 0, {}]]],\n",
              "   'name': 'y1_hidden_3'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'elu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L2',\n",
              "     'config': {'l2': 0.10000000149011612}},\n",
              "    'name': 'y0_hidden_4',\n",
              "    'trainable': True,\n",
              "    'units': 50,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['y0_hidden_3', 0, 0, {}]]],\n",
              "   'name': 'y0_hidden_4'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'elu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L2',\n",
              "     'config': {'l2': 0.10000000149011612}},\n",
              "    'name': 'y1_hidden_4',\n",
              "    'trainable': True,\n",
              "    'units': 50,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['y1_hidden_3', 0, 0, {}]]],\n",
              "   'name': 'y1_hidden_4'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'linear',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L2',\n",
              "     'config': {'l2': 0.10000000149011612}},\n",
              "    'name': 'y0_predictions',\n",
              "    'trainable': True,\n",
              "    'units': 1,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['y0_hidden_4', 0, 0, {}]]],\n",
              "   'name': 'y0_predictions'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'linear',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L2',\n",
              "     'config': {'l2': 0.10000000149011612}},\n",
              "    'name': 'y1_predictions',\n",
              "    'trainable': True,\n",
              "    'units': 1,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['y1_hidden_4', 0, 0, {}]]],\n",
              "   'name': 'y1_predictions'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'linear',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 't_prediction',\n",
              "    'trainable': True,\n",
              "    'units': 1,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['phi_2', 0, 0, {}]]],\n",
              "   'name': 't_prediction'},\n",
              "  {'class_name': 'Concatenate',\n",
              "   'config': {'axis': 1,\n",
              "    'dtype': 'float32',\n",
              "    'name': 'concatenate',\n",
              "    'trainable': True},\n",
              "   'inbound_nodes': [[['y0_predictions', 0, 0, {}],\n",
              "     ['y1_predictions', 0, 0, {}],\n",
              "     ['t_prediction', 0, 0, {}],\n",
              "     ['phi_2', 0, 0, {}]]],\n",
              "   'name': 'concatenate'}],\n",
              " 'name': 'model',\n",
              " 'output_layers': [['concatenate', 0, 0]]}"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save predicted result\n",
        "data_save_dragon=compute_prediction(data, best_dragon_model)\n",
        "np.save('./save/pred_result/tune_result_{}.npy'.format(\"dragonnet\" + '_' + \"IHDP\"), data_save_dragon) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNtmE_YIVuIV",
        "outputId": "fcca932b-b250-4e6d-832e-60f8e1088045"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual ATE: 3.8536534 \n",
            "\n",
            "\n",
            "Estimated ATE: 3.7764614 \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tune TARNet"
      ],
      "metadata": {
        "id": "fxC7FNJs3OtP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner as kt\n",
        "from keras_tuner.tuners import RandomSearch\n",
        "def make_hypertarnet(hp):\n",
        "    \"\"\"\n",
        "    Neural net predictive model. The dragon has three heads.\n",
        "    :param input_dim:\n",
        "    :param reg:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # hp.Choice takes hyperparam name, list of options, and default\n",
        "    reg_l2=hp.Choice('l2',[.1,.01,.001],default=.01)\n",
        "    input_dim=25\n",
        "    inputs = Input(shape=(input_dim,), name='input')\n",
        "\n",
        "    # representation\n",
        "    rep_units = hp.Choice('rep_units', [50,100,200],default=200)\n",
        "    phi = Dense(units=rep_units, activation='elu', kernel_initializer='RandomNormal',name='phi_1')(inputs)\n",
        "    for i in range(hp.Int('rep_layers', 1, 2,3, default=1)):\n",
        "      #pretty nifty way to dynamically add more layers!\n",
        "      phi = Dense(units=rep_units, activation='elu', kernel_initializer='RandomNormal',name='phi_'+str(i+2))(phi)\n",
        "\n",
        "    # HYPOTHESIS\n",
        "    hyp_units = hp.Choice('hyp_units', [20,50,100,200],default=100)\n",
        "    y0_hidden = Dense(units=hyp_units, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y0_hidden_1')(phi)\n",
        "    y1_hidden = Dense(units=hyp_units, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y1_hidden_1')(phi)\n",
        "    for i in range(hp.Int('hyp_layers', 1, 3, default=2)):\n",
        "      y0_hidden = Dense(units=hyp_units, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y0_hidden_'+str(i+2))(y0_hidden)\n",
        "      y1_hidden = Dense(units=hyp_units, activation='elu', kernel_regularizer=regularizers.l2(reg_l2),name='y1_hidden_'+str(i+2))(y1_hidden)\n",
        "    \n",
        "    # OUTPUT\n",
        "    y0_predictions = Dense(units=1, activation=None, kernel_regularizer=regularizers.l2(reg_l2), name='y0_predictions')(y0_hidden)\n",
        "    y1_predictions = Dense(units=1, activation=None, kernel_regularizer=regularizers.l2(reg_l2), name='y1_predictions')(y1_hidden)\n",
        "\n",
        "    concat_pred = Concatenate(1)([y0_predictions, y1_predictions,phi])\n",
        "    model = Model(inputs=inputs, outputs=concat_pred)\n",
        "    \n",
        "    sgd_lr = 1e-5\n",
        "    momentum = 0.9\n",
        "    \n",
        "    optimizer=SGD(lr=sgd_lr, momentum=momentum, nesterov=True)\n",
        "    \n",
        "    model.compile(optimizer=SGD(lr=sgd_lr, momentum=momentum, nesterov=True),\n",
        "                      loss=regression_loss,\n",
        "                 metrics=regression_loss)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "LJa6sZldWRzz"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_tuner.engine import tuner_utils\n",
        "from tensorboard.plugins.hparams import api as hparams_api\n",
        "!rm -rf tar_dir\n",
        "def regression_loss(concat_true, concat_pred):\n",
        "    #computes a standard MSE loss for TARNet\n",
        "    y_true = concat_true[:, 0] #get individual vectors\n",
        "    t_true = concat_true[:, 1]\n",
        " \n",
        "    y0_pred = concat_pred[:, 0]\n",
        "    y1_pred = concat_pred[:, 1]\n",
        " \n",
        "    #Each head outputs a prediction for both potential outcomes\n",
        "    #We use t_true as a switch to only calculate the factual loss\n",
        "    loss0 = tf.reduce_sum((1. - t_true) * tf.square(y_true - y0_pred))\n",
        "    loss1 = tf.reduce_sum(t_true * tf.square(y_true - y1_pred))\n",
        "    #note Shi uses tf.reduce_sum for her losses even though mathematically we should be using the mean\n",
        "    #tf.reduce_mean and tf.reduce_sum should be equivalent, but maybe having larger error gradients makes training easier?\n",
        "    return loss0 + loss1\n",
        "\n",
        "class TarNetTuner(kt.Tuner):\n",
        "\n",
        "  def run_trial(self, trial,dataset,*fit_args, **fit_kwargs):\n",
        "      # *args and **kwargs in Python are positional (list) and keyword (dict) arguments\n",
        "      verbose = fit_kwargs['verbose']\n",
        "\n",
        "      log_dir=self.project_dir+'/trial_'+trial.trial_id\n",
        "      hp = trial.hyperparameters\n",
        "      \n",
        "      batch_size = hp.Int('batch_size', 64, 256, step=64, default=64)\n",
        "      stopping_patience=hp.Int('batch_size', 5, 15, step=5, default=5)\n",
        "\n",
        "      #some of this hacky code will hopefully go away as Keras Tuner get's more polished\n",
        "      hparams = tuner_utils.convert_hyperparams_to_hparams(trial.hyperparameters)\n",
        "      file_writer = tf.summary.create_file_writer(log_dir + \"/metrics\")\n",
        "      file_writer.set_as_default()\n",
        "      \n",
        "      tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "      hparams_callback = hparams_api.KerasCallback(\n",
        "                        writer=log_dir,\n",
        "                        hparams=hparams,\n",
        "                        #I prepend trial_ here to get it to save nicely. Hopefully will be fixed in future version of KT.\n",
        "                        trial_id='trial_'+trial.trial_id) \n",
        "      metrics_callback=Base_Metrics(dataset,verbose=verbose)\n",
        "      callbacks = [\n",
        "              TerminateOnNaN(),\n",
        "              EarlyStopping(monitor='val_loss', patience=stopping_patience, min_delta=0.0001),\n",
        "              ReduceLROnPlateau(monitor='loss', factor=0.5, patience=5, verbose=verbose, mode='auto',\n",
        "                                min_delta=0, cooldown=0, min_lr=0),\n",
        "              metrics_callback,\n",
        "              tensorboard_callback,\n",
        "              hparams_callback\n",
        "          ]\n",
        "\n",
        "      \n",
        "      model = self.hypermodel.build(hp)\n",
        "      model.fit(x=fit_args[0],y=fit_args[1],\n",
        "                 callbacks=callbacks,\n",
        "                  validation_split=fit_kwargs['validation_split'],\n",
        "                  epochs=fit_kwargs['epochs'],\n",
        "                  batch_size=batch_size, verbose=verbose)\n",
        "      \n",
        "      #give the metric to the hyperparameter optimization algorithm\n",
        "      concat_pred=model.predict(data['x'])\n",
        "      pehe_nn=metrics_callback.PEHEnn(concat_pred)\n",
        "      self.oracle.update_trial(trial.trial_id, {'cate_nn_err': tf.sqrt(pehe_nn)})\n",
        "      self.save_model(trial.trial_id, model)\n"
      ],
      "metadata": {
        "id": "lchkzsg1Wapm"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = TarNetTuner(\n",
        "    #the oracle is the hyperoptimization algorithm\n",
        "    oracle=kt.oracles.BayesianOptimization(\n",
        "        objective=kt.Objective('cate_nn_err', 'min'),\n",
        "        max_trials=10, #were trying to keep this quick for you.\n",
        "        #You probably want to do as many trials as your resources allow if you see variance between runs\n",
        "        seed=0    \n",
        "),\n",
        "        directory='tar_dir',\n",
        "        project_name='tar_tune',\n",
        "    hypermodel=make_hypertarnet\n",
        "    )\n",
        "tuner.search(data, data['x'],yt, epochs=300,validation_split=.2,verbose=2)\n",
        "\n",
        "best_trial=tuner.oracle.get_best_trials(num_trials=1)[0]\n",
        "print(\"BEST TRIAL ID:\",best_trial.trial_id)\n",
        "best_tar_model=tuner.load_model(best_trial)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X65DLJakWdLJ",
        "outputId": "43081461-9348-47fd-8292-27d41b79abb6"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 10 Complete [00h 01m 23s]\n",
            "cate_nn_err: 1.5489557981491089\n",
            "\n",
            "Best cate_nn_err So Far: 1.5489557981491089\n",
            "Total elapsed time: 00h 13m 46s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "BEST TRIAL ID: 130b7323bdcb7146bfbd44961b2390fb\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_tar_model.get_config()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_BUT0k8uXkX",
        "outputId": "c8c421f2-5ea6-4b54-ac1f-3133b48fe054"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_layers': [['input', 0, 0]],\n",
              " 'layers': [{'class_name': 'InputLayer',\n",
              "   'config': {'batch_input_shape': (None, 25),\n",
              "    'dtype': 'float32',\n",
              "    'name': 'input',\n",
              "    'ragged': False,\n",
              "    'sparse': False},\n",
              "   'inbound_nodes': [],\n",
              "   'name': 'input'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'elu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'RandomNormal',\n",
              "     'config': {'mean': 0.0, 'seed': None, 'stddev': 0.05}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'phi_1',\n",
              "    'trainable': True,\n",
              "    'units': 50,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['input', 0, 0, {}]]],\n",
              "   'name': 'phi_1'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'elu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'RandomNormal',\n",
              "     'config': {'mean': 0.0, 'seed': None, 'stddev': 0.05}},\n",
              "    'kernel_regularizer': None,\n",
              "    'name': 'phi_2',\n",
              "    'trainable': True,\n",
              "    'units': 50,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['phi_1', 0, 0, {}]]],\n",
              "   'name': 'phi_2'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'elu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L2',\n",
              "     'config': {'l2': 0.10000000149011612}},\n",
              "    'name': 'y0_hidden_1',\n",
              "    'trainable': True,\n",
              "    'units': 200,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['phi_2', 0, 0, {}]]],\n",
              "   'name': 'y0_hidden_1'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'elu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L2',\n",
              "     'config': {'l2': 0.10000000149011612}},\n",
              "    'name': 'y1_hidden_1',\n",
              "    'trainable': True,\n",
              "    'units': 200,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['phi_2', 0, 0, {}]]],\n",
              "   'name': 'y1_hidden_1'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'elu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L2',\n",
              "     'config': {'l2': 0.10000000149011612}},\n",
              "    'name': 'y0_hidden_2',\n",
              "    'trainable': True,\n",
              "    'units': 200,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['y0_hidden_1', 0, 0, {}]]],\n",
              "   'name': 'y0_hidden_2'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'elu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L2',\n",
              "     'config': {'l2': 0.10000000149011612}},\n",
              "    'name': 'y1_hidden_2',\n",
              "    'trainable': True,\n",
              "    'units': 200,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['y1_hidden_1', 0, 0, {}]]],\n",
              "   'name': 'y1_hidden_2'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'elu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L2',\n",
              "     'config': {'l2': 0.10000000149011612}},\n",
              "    'name': 'y0_hidden_3',\n",
              "    'trainable': True,\n",
              "    'units': 200,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['y0_hidden_2', 0, 0, {}]]],\n",
              "   'name': 'y0_hidden_3'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'elu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L2',\n",
              "     'config': {'l2': 0.10000000149011612}},\n",
              "    'name': 'y1_hidden_3',\n",
              "    'trainable': True,\n",
              "    'units': 200,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['y1_hidden_2', 0, 0, {}]]],\n",
              "   'name': 'y1_hidden_3'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'elu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L2',\n",
              "     'config': {'l2': 0.10000000149011612}},\n",
              "    'name': 'y0_hidden_4',\n",
              "    'trainable': True,\n",
              "    'units': 200,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['y0_hidden_3', 0, 0, {}]]],\n",
              "   'name': 'y0_hidden_4'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'elu',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L2',\n",
              "     'config': {'l2': 0.10000000149011612}},\n",
              "    'name': 'y1_hidden_4',\n",
              "    'trainable': True,\n",
              "    'units': 200,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['y1_hidden_3', 0, 0, {}]]],\n",
              "   'name': 'y1_hidden_4'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'linear',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L2',\n",
              "     'config': {'l2': 0.10000000149011612}},\n",
              "    'name': 'y0_predictions',\n",
              "    'trainable': True,\n",
              "    'units': 1,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['y0_hidden_4', 0, 0, {}]]],\n",
              "   'name': 'y0_predictions'},\n",
              "  {'class_name': 'Dense',\n",
              "   'config': {'activation': 'linear',\n",
              "    'activity_regularizer': None,\n",
              "    'bias_constraint': None,\n",
              "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
              "    'bias_regularizer': None,\n",
              "    'dtype': 'float32',\n",
              "    'kernel_constraint': None,\n",
              "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
              "     'config': {'seed': None}},\n",
              "    'kernel_regularizer': {'class_name': 'L2',\n",
              "     'config': {'l2': 0.10000000149011612}},\n",
              "    'name': 'y1_predictions',\n",
              "    'trainable': True,\n",
              "    'units': 1,\n",
              "    'use_bias': True},\n",
              "   'inbound_nodes': [[['y1_hidden_4', 0, 0, {}]]],\n",
              "   'name': 'y1_predictions'},\n",
              "  {'class_name': 'Concatenate',\n",
              "   'config': {'axis': 1,\n",
              "    'dtype': 'float32',\n",
              "    'name': 'concatenate',\n",
              "    'trainable': True},\n",
              "   'inbound_nodes': [[['y0_predictions', 0, 0, {}],\n",
              "     ['y1_predictions', 0, 0, {}],\n",
              "     ['phi_2', 0, 0, {}]]],\n",
              "   'name': 'concatenate'}],\n",
              " 'name': 'model',\n",
              " 'output_layers': [['concatenate', 0, 0]]}"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save predicted result\n",
        "data_save_tar=compute_prediction(data, best_tar_model)\n",
        "np.save('./save/pred_result/tune_result_{}.npy'.format(\"tarnet\" + '_' + \"IHDP\"), data_save_tar) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OW7pzD0sXTon",
        "outputId": "32329237-b49f-44f4-b98c-85853124970b"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual ATE: 3.8536534 \n",
            "\n",
            "\n",
            "Estimated ATE: 3.7309685 \n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}